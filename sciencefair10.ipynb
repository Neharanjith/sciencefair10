{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neharanjith/sciencefair10/blob/main/sciencefair10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sRUGcVoJPklM",
        "outputId": "ce68e1e2-d69f-4fc9-f207-fd233d10deee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit_calendar\n",
            "  Downloading streamlit_calendar-1.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting streamlit<2.0.0,>=1.12.0 (from streamlit_calendar)\n",
            "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (5.29.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit<2.0.0,>=1.12.0->streamlit_calendar)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit<2.0.0,>=1.12.0->streamlit_calendar)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit<2.0.0,>=1.12.0->streamlit_calendar) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (1.31.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit<2.0.0,>=1.12.0->streamlit_calendar) (1.17.0)\n",
            "Downloading streamlit_calendar-1.2.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit, streamlit_calendar\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.43.2 streamlit_calendar-1.2.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as pt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "!pip install streamlit_calendar\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras.optimizers.legacy import Adagrad\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization,Bidirectional, GaussianNoise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jxLf7JqLz4V"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENcDDQLKPuaH"
      },
      "outputs": [],
      "source": [
        "year07 = pd.read_csv('2007_CELIAS_Proton_Monitor_5min.csv')\n",
        "year08 = pd.read_csv('2008_CELIAS_Proton_Monitor_5min.csv')\n",
        "year09 = pd.read_csv('2009_CELIAS_Proton_Monitor_5min.csv')\n",
        "year10 = pd.read_csv('2010_CELIAS_Proton_Monitor_5min.csv')\n",
        "year11 = pd.read_csv('2011_CELIAS_Proton_Monitor_5min.csv')\n",
        "year12 = pd.read_csv('2012_CELIAS_Proton_Monitor_5min.csv')\n",
        "year13 = pd.read_csv('2013_CELIAS_Proton_Monitor_5min.csv')\n",
        "year14 = pd.read_csv('2014_CELIAS_Proton_Monitor_5min.csv')\n",
        "year15 = pd.read_csv('2015_CELIAS_Proton_Monitor_5min.csv')\n",
        "year16 = pd.read_csv('2016_CELIAS_Proton_Monitor_5min.csv')\n",
        "year17 = pd.read_csv('2017_CELIAS_Proton_Monitor_5min.csv')\n",
        "year18 = pd.read_csv('2018_CELIAS_Proton_Monitor_5min.csv')\n",
        "year19 = pd.read_csv('2019_CELIAS_Proton_Monitor_5min.csv')\n",
        "year20 = pd.read_csv('2020_CELIAS_Proton_Monitor_5min.csv')\n",
        "year21 = pd.read_csv('2021_CELIAS_Proton_Monitor_5min.csv')\n",
        "year22 = pd.read_csv('2022_CELIAS_Proton_Monitor_5min.csv')\n",
        "year23 = pd.read_csv('2023_CELIAS_Proton_Monitor_5min.csv')\n",
        "dataset = pd.concat([year07, year08,year09,year10,year11,year12,year13,year14,year15,year16,year17,year18,year19,year20,year21,year22,year23], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPJX1yqpPyoL"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(dataset) * .7) -5\n",
        "val_size = int(len(dataset) * .15)\n",
        "test_size = len(dataset) - train_size - val_size + 5\n",
        "train = dataset.iloc[0:train_size, :]\n",
        "val = dataset.iloc[train_size:train_size + val_size, :]\n",
        "test = dataset.iloc[train_size + val_size:, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD8ZedQw0ky7",
        "outputId": "01c61e43-0112-4169-bb58-7c5c4dfe6ca1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-3031da7767d5>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['SPEED'] = scaled_speed_train\n",
            "<ipython-input-5-3031da7767d5>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val['SPEED'] = scaled_speed_val\n",
            "<ipython-input-5-3031da7767d5>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['SPEED'] = scaled_speed_test\n",
            "<ipython-input-5-3031da7767d5>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['YY'] = scaled_yearss_train\n",
            "<ipython-input-5-3031da7767d5>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val['YY'] = scaled_yearss_val\n",
            "<ipython-input-5-3031da7767d5>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['YY'] = scaled_yearss_test\n",
            "<ipython-input-5-3031da7767d5>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['Np'] = scaled_nps_train\n",
            "<ipython-input-5-3031da7767d5>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val['Np'] = scaled_nps_val\n",
            "<ipython-input-5-3031da7767d5>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['Np'] = scaled_nps_test\n",
            "<ipython-input-5-3031da7767d5>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['N/S'] = scaled_n_ss_train\n",
            "<ipython-input-5-3031da7767d5>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val['N/S'] = scaled_n_ss_val\n",
            "<ipython-input-5-3031da7767d5>:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['N/S'] = scaled_n_ss_test\n",
            "<ipython-input-5-3031da7767d5>:68: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['MON'] = scaled_months_train\n",
            "<ipython-input-5-3031da7767d5>:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['MON'] = scaled_months_test\n",
            "<ipython-input-5-3031da7767d5>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val['MON'] = scaled_months_val\n",
            "<ipython-input-5-3031da7767d5>:72: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['DY'] = scaled_days_train\n",
            "<ipython-input-5-3031da7767d5>:73: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['DY'] = scaled_days_test\n",
            "<ipython-input-5-3031da7767d5>:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val['DY'] = scaled_days_val\n",
            "<ipython-input-5-3031da7767d5>:76: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train.drop(['DOY:HH:MM:SS','Vth','V_He','GSE_X','GSE_Y','GSE_Z','RANGE','CRN(E)','HGLAT','HGLONG'],axis=1,inplace=True)\n",
            "<ipython-input-5-3031da7767d5>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test.drop(['DOY:HH:MM:SS','Vth','V_He','GSE_X','GSE_Y','GSE_Z','RANGE','CRN(E)','HGLAT','HGLONG'],axis=1,inplace=True)\n",
            "<ipython-input-5-3031da7767d5>:78: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val.drop(['DOY:HH:MM:SS','Vth','V_He','GSE_X','GSE_Y','GSE_Z','RANGE','CRN(E)','HGLAT','HGLONG'],axis=1,inplace=True)\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_speed = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_speed_train = scaler_speed.fit_transform(train[['SPEED']])\n",
        "scaled_speed_val = scaler_speed.fit_transform(val[['SPEED']])\n",
        "scaled_speed_test = scaler_speed.fit_transform(test[['SPEED']])\n",
        "\n",
        "\n",
        "dataset['YY'] = dataset['YY'] + 2000\n",
        "scaler_yearss = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_yearss_train = scaler_yearss.fit_transform(train[['YY']])\n",
        "scaled_yearss_val = scaler_yearss.fit_transform(val[['YY']])\n",
        "scaled_yearss_test = scaler_yearss.fit_transform(test[['YY']])\n",
        "\n",
        "\n",
        "scaler_nps = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_nps_train = scaler_nps.fit_transform(train[['Np']])\n",
        "scaled_nps_val = scaler_nps.fit_transform(val[['Np']])\n",
        "scaled_nps_test = scaler_nps.fit_transform(test[['Np']])\n",
        "\n",
        "\n",
        "scaler_n_ss = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_n_ss_train = scaler_n_ss.fit_transform(train[['N/S']])\n",
        "scaled_n_ss_val = scaler_n_ss.fit_transform(val[['N/S']])\n",
        "scaled_n_ss_test = scaler_n_ss.fit_transform(test[['N/S']])\n",
        "\n",
        "\n",
        "train['SPEED'] = scaled_speed_train\n",
        "val['SPEED'] = scaled_speed_val\n",
        "test['SPEED'] = scaled_speed_test\n",
        "\n",
        "train['YY'] = scaled_yearss_train\n",
        "val['YY'] = scaled_yearss_val\n",
        "test['YY'] = scaled_yearss_test\n",
        "\n",
        "train['Np'] = scaled_nps_train\n",
        "val['Np'] = scaled_nps_val\n",
        "test['Np'] = scaled_nps_test\n",
        "\n",
        "train['N/S'] = scaled_n_ss_train\n",
        "val['N/S'] = scaled_n_ss_val\n",
        "test['N/S'] = scaled_n_ss_test\n",
        "\n",
        "\n",
        "def encode_month(month):\n",
        "    angle = (month - 1) / 11 * 2 * np.pi\n",
        "    cos_value = np.cos(angle)\n",
        "    return cos_value\n",
        "\n",
        "days_month = 30\n",
        "def encode_day(day, month):\n",
        "    days_month = 30\n",
        "    if month == 1 or month == 3 or month == 5 or month == 7 or month == 8 or month == 10 or month == 12:\n",
        "        days_month = 31\n",
        "    elif month == 2:\n",
        "      days_month = 28\n",
        "    day_cos = np.cos(2 * np.pi * day / days_month)\n",
        "    return day_cos\n",
        "\n",
        "\n",
        "scaled_months_train = train['MON'].apply(encode_month)\n",
        "scaled_months_test = test['MON'].apply(encode_month)\n",
        "scaled_months_val = val['MON'].apply(encode_month)\n",
        "\n",
        "scaled_days_train = train['DY'].combine(train['MON'], lambda day, month: encode_day(day, month))\n",
        "scaled_days_test = test['DY'].combine(test['MON'], lambda day, month: encode_day(day, month))\n",
        "scaled_days_val = val['DY'].combine(val['MON'], lambda day, month: encode_day(day, month))\n",
        "\n",
        "train['MON'] = scaled_months_train\n",
        "test['MON'] = scaled_months_test\n",
        "val['MON'] = scaled_months_val\n",
        "\n",
        "train['DY'] = scaled_days_train\n",
        "test['DY'] = scaled_days_test\n",
        "val['DY'] = scaled_days_val\n",
        "\n",
        "train.drop(['DOY:HH:MM:SS','Vth','V_He','GSE_X','GSE_Y','GSE_Z','RANGE','CRN(E)','HGLAT','HGLONG'],axis=1,inplace=True)\n",
        "test.drop(['DOY:HH:MM:SS','Vth','V_He','GSE_X','GSE_Y','GSE_Z','RANGE','CRN(E)','HGLAT','HGLONG'],axis=1,inplace=True)\n",
        "val.drop(['DOY:HH:MM:SS','Vth','V_He','GSE_X','GSE_Y','GSE_Z','RANGE','CRN(E)','HGLAT','HGLONG'],axis=1,inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-giV2pA93K4f"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset, look_back=6):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(len(dataset) - look_back):\n",
        "        a = dataset.iloc[i: i + look_back, :].values\n",
        "        dataX.append(a)\n",
        "        b = dataset.iloc[i + 1: i + look_back + 1, :].values\n",
        "        dataY.append(b)\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "look_back = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJWMEwXcQqFq"
      },
      "outputs": [],
      "source": [
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "valX, valY = create_dataset(val, look_back)\n",
        "\n",
        "trainY = np.reshape(trainY,(int(trainY.shape[0]),6, 6))\n",
        "testY = np.reshape(testY,(int(testY.shape[0]),6, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAKbUkKCQvRp",
        "outputId": "c6429097-3f71-4502-ff8b-e4fec5f771e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 90ms/step - loss: 0.0932\n",
            "Epoch 2/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 90ms/step - loss: 0.0805\n",
            "Epoch 3/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 88ms/step - loss: 0.0798\n",
            "Epoch 4/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 88ms/step - loss: 0.0796\n",
            "Epoch 5/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 88ms/step - loss: 0.0796\n",
            "Epoch 6/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 88ms/step - loss: 0.0794\n",
            "Epoch 7/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 88ms/step - loss: 0.0794\n",
            "Epoch 8/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 88ms/step - loss: 0.0797\n",
            "Epoch 9/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 88ms/step - loss: 0.0794\n",
            "Epoch 10/10\n",
            "\u001b[1m3884/3884\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 88ms/step - loss: 0.0794\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x789b69685850>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(1, look_back)))\n",
        "model.add((LSTM(units=65,return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=65,return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=65,return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=65,return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(GaussianNoise(0.01))\n",
        "model.add(Dropout(0.0008))\n",
        "model.add(Dense(6,activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "model.compile(loss='mean_squared_error', optimizer= \"Adam\")\n",
        "model.fit(trainX, trainY, epochs=10, batch_size=288, validation_data=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJQL53QBZrfo",
        "outputId": "aeccebe4-cf4d-48d1-c09c-0867404c1a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34954/34954\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 6ms/step\n",
            "\u001b[1m7491/7491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 7ms/step\n",
            "Train Score: 0.28 RMSE\n",
            "Test Score: 0.27 RMSE\n"
          ]
        }
      ],
      "source": [
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "original_shapeY = trainY.shape\n",
        "original_testY = testY.shape\n",
        "\n",
        "trainY_reshaped = trainY.reshape(-1, original_shapeY[2])\n",
        "testY_reshaped = testY.reshape(-1, original_testY[2])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 2))\n",
        "scaler.fit(trainY_reshaped)\n",
        "\n",
        "trainPredict = scaler.inverse_transform(trainPredict.reshape(-1, trainPredict.shape[2]))\n",
        "trainPredict = trainPredict.reshape(original_shapeY)\n",
        "\n",
        "testPredict = scaler.inverse_transform(testPredict.reshape(-1, testPredict.shape[2]))\n",
        "testPredict = testPredict.reshape(original_testY)\n",
        "\n",
        "trainY = scaler.inverse_transform(trainY_reshaped)\n",
        "trainY = trainY.reshape(-1, original_shapeY[1], original_shapeY[2])\n",
        "\n",
        "testY = scaler.inverse_transform(testY_reshaped)\n",
        "testY = testY.reshape(-1, original_testY[1], original_testY[2])\n",
        "\n",
        "trainScore = np.sqrt(mean_squared_error(trainY.reshape(-1, trainY.shape[2]),trainPredict.reshape(-1, trainPredict.shape[2])))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = np.sqrt(mean_squared_error(testY.reshape(-1, testY.shape[2]),testPredict.reshape(-1, testPredict.shape[2])))\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OFxtABaQHTFJ"
      },
      "outputs": [],
      "source": [
        "predicted_values = []\n",
        "middle = 1438098\n",
        "\n",
        "testX = np.reshape(testX, (1, middle, 6))\n",
        "current_input = testX.copy()\n",
        "\n",
        "batch_size = 288\n",
        "total_iterations = 261792\n",
        "std_dev = 0.1\n",
        "\n",
        "for batch_start in range(0, total_iterations, batch_size):\n",
        "    batch_predictions = []  # Reset for each batch\n",
        "\n",
        "    for _ in range(batch_size):\n",
        "        last_time_step = current_input[:, -1:, :]  # Take the last known time step\n",
        "\n",
        "        predicted_value = model.predict(last_time_step, verbose=0)\n",
        "\n",
        "        # Apply stochastic sampling\n",
        "        sampled_value = np.random.normal(loc=predicted_value[0], scale=std_dev)\n",
        "\n",
        "        # Ensure correct shape\n",
        "        sampled_value = np.reshape(sampled_value, (1, 1, current_input.shape[-1]))\n",
        "\n",
        "        # Shift input window and insert the new sampled value\n",
        "        current_input = np.roll(current_input, shift=-1, axis=1)\n",
        "        current_input[0, -1, :] = sampled_value\n",
        "\n",
        "        batch_predictions.append(sampled_value)\n",
        "\n",
        "    # Append only the new batch's predictions\n",
        "    predicted_values.extend(batch_predictions)\n",
        "\n",
        "# Convert list to array\n",
        "predicted_values = np.vstack(predicted_values).reshape(-1, 6)\n",
        "\n",
        "\n",
        "\n",
        "predicted_values[:, 3] = scaler_speed.inverse_transform(predicted_values[:, 3].reshape(-1, 1)).flatten()\n",
        "predicted_values[:, 0] = scaler_yearss.inverse_transform(predicted_values[:, 0].reshape(-1, 1)).flatten()\n",
        "predicted_values[:, 4] = scaler_nps.inverse_transform(predicted_values[:, 4].reshape(-1, 1)).flatten()\n",
        "predicted_values[:, 5] = scaler_n_ss.inverse_transform(predicted_values[:, 5].reshape(-1, 1)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hm2C9EOo2Ul5"
      },
      "outputs": [],
      "source": [
        "speed_values = []\n",
        "np_values = []\n",
        "ns_values = []\n",
        "final = []\n",
        "newfinal = []\n",
        "count = 0\n",
        "\n",
        "# 0 is not visible, 1 is semi visible, 2 is very visible\n",
        "for i, step in enumerate(predicted_values):\n",
        "     final_speed = 0\n",
        "     final_np = 0\n",
        "     final_ns = 0\n",
        "     if step[3] >= 400 and step[3] < 600:\n",
        "       final_speed = 1\n",
        "     elif step[3] >= 600:\n",
        "       final_speed = 2\n",
        "     if step[4] >= 20 and step[4] < 40:\n",
        "       final_np = 1\n",
        "     elif step[4] >= 40:\n",
        "       final_np = 2\n",
        "     if step[5] < 0:\n",
        "       final_ns = 2\n",
        "     sum = final_speed + final_np + final_ns\n",
        "     if sum <= 2:\n",
        "       final.append((\"not visible\"))\n",
        "     elif sum <5:\n",
        "       final.append((\"semi visible\"))\n",
        "     else:\n",
        "       final.append((\"very visible\"))\n",
        "\n",
        "for i in range(0, len(final), 288):  # Process in chunks of 288\n",
        "  count = 0\n",
        "  for j in range(i, min(i + 288, len(final))):\n",
        "    if j % 288 < 48 or j % 288 > 204:\n",
        "        if final[j] == \"semi visible\":\n",
        "            count += 1\n",
        "        elif final[j] == \"very visible\":\n",
        "            count += 2\n",
        "  if count >= 100:\n",
        "      newfinal.append(\"very visible\")\n",
        "  elif count >= 60:\n",
        "      newfinal.append(\"semi visible\")\n",
        "  else:\n",
        "      newfinal.append(\"not visible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hbduSBhKjsUO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# âœ… Save `newfinal` to a text file and check if it was written correctly\n",
        "file_path = \"newfinal.txt\"\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for item in newfinal:\n",
        "        f.write(item + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lDAOONjLRfDI",
        "outputId": "af1a10f1-b4c6-44ad-bab2-04933c2f7b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from streamlit_calendar import calendar\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "file_path = \"newfinal.txt\"\n",
        "if os.path.exists(file_path):\n",
        "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    newfinal = [line.strip() for line in f]\n",
        "else:\n",
        "  st.error(\"error\")\n",
        "\n",
        "st.set_page_config(page_title=\"CELESTIA\", page_icon=\"ğŸŒŒ\")\n",
        "\n",
        "st.title(\"CELESTIA\")\n",
        "\n",
        "# Only allow 'multimonth' calendar mode\n",
        "mode = \"multimonth\"\n",
        "\n",
        "visibility_colors = {\n",
        "    \"very visible\": \"#9b3eed\",\n",
        "    \"semi visible\": \"#b57de8\",\n",
        "    \"not visible\": \"#d8bdf0\",\n",
        "}\n",
        "\n",
        "# Start date (July 7, 2023)\n",
        "start_date = datetime(2023, 7, 7)\n",
        "\n",
        "# Generate events based on `newfinal` list (each index = a new day)\n",
        "events = []\n",
        "for i, visibility in enumerate(newfinal):\n",
        "    event_start = start_date + timedelta(days=i)  # Each index corresponds to an exact date\n",
        "\n",
        "    event = {\n",
        "        \"title\": visibility.capitalize(),  # Convert to \"Very Visible\", \"Semi Visible\", etc.\n",
        "        \"color\": visibility_colors[visibility],  # Assign the correct color\n",
        "        \"start\": event_start.strftime(\"%Y-%m-%d\"),\n",
        "        \"end\": event_start.strftime(\"%Y-%m-%d\"),  # Single-day event\n",
        "        \"resourceId\": chr(97 + (i % 6)),  # Cycle through resource IDs (a-f)\n",
        "    }\n",
        "    events.append(event)\n",
        "\n",
        "# Define calendar resources\n",
        "calendar_resources = [\n",
        "    {\"id\": \"a\", \"building\": \"Building A\", \"title\": \"Room A\"},\n",
        "    {\"id\": \"b\", \"building\": \"Building A\", \"title\": \"Room B\"},\n",
        "    {\"id\": \"c\", \"building\": \"Building B\", \"title\": \"Room C\"},\n",
        "    {\"id\": \"d\", \"building\": \"Building B\", \"title\": \"Room D\"},\n",
        "    {\"id\": \"e\", \"building\": \"Building C\", \"title\": \"Room E\"},\n",
        "    {\"id\": \"f\", \"building\": \"Building C\", \"title\": \"Room F\"},\n",
        "]\n",
        "\n",
        "# Calendar options\n",
        "calendar_options = {\n",
        "    \"editable\": True,\n",
        "    \"navLinks\": True,\n",
        "    \"resources\": calendar_resources,\n",
        "    \"selectable\": True,\n",
        "    \"initialView\": \"multiMonthYear\",\n",
        "}\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "        .fc-day-today {\n",
        "            background-color: #6632a8 !important;\n",
        "            color: white !important;  /* Change text color if needed */\n",
        "        }\n",
        "        /* Change the color of the previous and next buttons (arrows) */\n",
        "        .fc-prev-button, .fc-next-button {\n",
        "            color: #6632a8 !important;  /* Set your desired arrow color */\n",
        "            background-color: transparent !important;  /* Make the background transparent */\n",
        "            border: none !important;  /* Remove borders if needed */\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "# Render the calendar with updated event titles\n",
        "state = calendar(\n",
        "    events=st.session_state.get(\"events\", events),\n",
        "    options=calendar_options,\n",
        "    custom_css=\"\"\"\n",
        "    .fc-event-past {\n",
        "        opacity: 0.8;\n",
        "    }\n",
        "    .fc-event-time {\n",
        "        font-style: italic;\n",
        "    }\n",
        "    .fc-event-title {\n",
        "        font-weight: 700;\n",
        "    }\n",
        "    .fc-toolbar-title {\n",
        "        font-size: 2rem;\n",
        "    }\n",
        "    \"\"\",\n",
        "    key=mode,\n",
        ")\n",
        "\n",
        "# Store updated events in session state if changed\n",
        "if state.get(\"eventsSet\") is not None:\n",
        "    st.session_state[\"events\"] = state[\"eventsSet\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SaEgPEcIRf9N",
        "outputId": "b62d4f1a-ad08-46bc-9426-7e37b9b5bc34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT3yvmDoRihp"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkFjczH6nlsX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}